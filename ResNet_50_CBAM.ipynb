{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUSt-yOA8Eo3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, History, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, AveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, ZeroPadding2D, Add\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers, regularizers\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "#from tensorflow_addons import metrics\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "from random import shuffle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9fylDZr_EzV"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Hfnw_KN_E2g"
      },
      "outputs": [],
      "source": [
        "def res_identity(x, filters, kern= None): \n",
        "  #renet block where dimension doesnot change.\n",
        "  #The skip connection is just simple identity conncection\n",
        "  #we will have 3 blocks and then input will be added\n",
        "\n",
        "  x_skip = x # this will be used for addition with the residual block \n",
        "  f1, f2 = filters\n",
        "\n",
        "  #first block \n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=kern)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  #second block # bottleneck (but size kept same with padding)\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=kern)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # third block activation used after adding the input\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=kern)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # add the input \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TKQ2kTv_E85"
      },
      "outputs": [],
      "source": [
        "def res_conv(x, s, filters, kern= None):\n",
        "  '''\n",
        "  here the input size changes''' \n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "\n",
        "  # first block\n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=kern)(x)\n",
        "  # when s = 2 then it is like downsizing the feature map\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # second block\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=kern)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=kern)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # shortcut \n",
        "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=kern)(x_skip)\n",
        "  x_skip = BatchNormalization()(x_skip)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x_skip = Activation('relu')(x_skip)\n",
        "\n",
        "  # add \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def channel_attention(f, filtros: int, ratio: int= 1, nombre: str= None):\n",
        "  reduccion= int(filtros // ratio)\n",
        "  Favr= tf.reduce_mean(f, axis= [-1], keepdims= True)\n",
        "  Fmax= tf.reduce_max(f, axis=[-1], keepdims= True)\n",
        "\n",
        "  Davr_r= Dense(reduccion, activation= 'relu')(Favr)\n",
        "  Dmax_r= Dense(reduccion, activation= 'relu')(Fmax)\n",
        "\n",
        "  Davr_a= Dense(filtros, activation= 'relu')(Davr_r)\n",
        "  Dmax_a= Dense(filtros, activation= 'relu')(Dmax_r)\n",
        "  \n",
        "  return Activation('sigmoid', name= nombre)(tf.add(Davr_a, Dmax_a))\n",
        "\n",
        "\n",
        "def spatial_attention(f, kernel_s: int= 7, nombre: str= None):\n",
        "  Favr= tf.reduce_mean(f, axis= [-1], keepdims= True)\n",
        "  Fmax= tf.reduce_max(f, axis= [-1], keepdims= True)\n",
        "\n",
        "  C_am= tf.concat([Favr, Fmax], axis= -1)\n",
        "\n",
        "  Ms= Conv2D(1, kernel_size= kernel_s, padding= 'same')(C_am)\n",
        "  Ms= BatchNormalization()(Ms)\n",
        "\n",
        "  return Activation('sigmoid', name= nombre)(Ms)\n",
        "\n",
        "\n",
        "def CBAM(f, nombre: str= None):\n",
        "  f_1= channel_attention(f, f.shape[-1], 16)\n",
        "  r_1= tf.math.multiply(f, f_1)\n",
        "  \n",
        "  f_2= spatial_attention(r_1)\n",
        "  r_2= tf.math.multiply(r_1, f_2)\n",
        "\n",
        "  return tf.add(f, r_2, name= nombre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0ORKhNy_E_X"
      },
      "outputs": [],
      "source": [
        "input_im = Input(shape=(480, 480, 3)) # cifar 10 images size\n",
        "x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
        "\n",
        "  # 1st stage\n",
        "  # here we perform maxpooling, see the figure above\n",
        "\n",
        "x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "  #2nd stage \n",
        "  # frm here on only conv block and identity block, no pooling\n",
        "\n",
        "x = res_conv(x, s=1, filters=(64, 256))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(64, 256))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(64, 256))\n",
        "x= CBAM(x)\n",
        "  # 3rd stage\n",
        "\n",
        "x = res_conv(x, s=2, filters=(128, 512))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(128, 512))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(128, 512))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(128, 512))\n",
        "\n",
        "  # 4th stage\n",
        "\n",
        "x = res_conv(x, s=2, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "\n",
        "\n",
        "  # 5th stage\n",
        "\n",
        "x = res_conv(x, s=2, filters=(512, 2048), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(512, 2048), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(512, 2048), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "\n",
        "  # ends with average pooling and dense connection\n",
        "\n",
        "x = AveragePooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "#x = Dense(4096, activation= \"relu\")(x)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)#, kernel_initializer='he_normal')(x) #multi-class\n",
        "\n",
        "  # define the model \n",
        "\n",
        "model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "#tf.keras.models.save_model(model, \"/content/drive/MyDrive/Proyectos/Sharon/Modelos guardados/ResNet50/ResNet50.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvYwo9d3ktNX"
      },
      "outputs": [],
      "source": [
        "#!unzip \"/content/drive/MyDrive/Sharon/Base de datos/Base_Procesada_Mecidor/Val/Val.zip\" -d \"/content/sample_data/\"\n",
        "#!unzip \"/content/drive/MyDrive/Sharon/Base de datos/Base_Procesada_Mecidor/Ent/Ent.zip\" -d \"/content/sample_data/\"\n",
        "\n",
        "#Kaggle\n",
        "!unzip \"/content/drive/MyDrive/Sharon/Base de datos/Kaggle/Val.zip\" -d \"/content/sample_data/\"\n",
        "!unzip \"/content/drive/MyDrive/Sharon/Base de datos/Kaggle/Ent.zip\" -d \"/content/sample_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOtKir-2_FGU"
      },
      "outputs": [],
      "source": [
        "input_dir= \"/content/sample_data/Ent\"\n",
        "target_dir= \"/content/sample_data/Val\"\n",
        "\n",
        "generador_ent= ImageDataGenerator(rescale= 1/255.0)\n",
        "generador_val= ImageDataGenerator(rescale= 1/255.0)\n",
        "\n",
        "\n",
        "ent_gen= generador_ent.flow_from_directory(input_dir,\n",
        "                                           class_mode= 'binary',\n",
        "                                           target_size=(480, 480),\n",
        "                                           batch_size= 1,\n",
        "                                           color_mode= \"rgb\",\n",
        "                                           shuffle= True,\n",
        "                                           )\n",
        "\n",
        "val_gen= generador_val.flow_from_directory(target_dir,\n",
        "                                           class_mode= 'binary',\n",
        "                                           target_size=(480, 480),\n",
        "                                           color_mode= \"rgb\",\n",
        "                                           batch_size= 1,\n",
        "                                           shuffle= True,\n",
        "                                           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1L7zMvq_FJJ"
      },
      "outputs": [],
      "source": [
        "def entrenamient_modelo(train_gen, val_gen, DIR_save, epocas= 30):\n",
        "\n",
        "    #class_weights = {0:1., 1:3.}\n",
        "\n",
        "    #Generamos los callback necesarios\n",
        "    checkpoint= ModelCheckpoint(DIR_save+ \"09122021_CBAM.hdf5\", monitor= 'val_loss', save_best_only= True, mode= 'min', save_weights_only= False)\n",
        "    reduceLROnPlat= ReduceLROnPlateau(monitor= 'val_loss', factor= 0.8, patience= 15, min_delta= 0.001, cooldown= 10, min_lr= 0.00001)\n",
        "    tensorboard_callback = TensorBoard(log_dir= datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    callbacks= [EarlyStopping(patience= 30,  monitor='val_loss'), checkpoint, tensorboard_callback, reduceLROnPlat]\n",
        "    metrica= [tf.keras.metrics.AUC(),\n",
        "              tf.keras.metrics.BinaryAccuracy(),\n",
        "              tf.keras.metrics.Recall(),\n",
        "              tf.keras.metrics.Precision()]\n",
        "\n",
        "    #Compilamos con la funcion perdida y el optimizador que utilizaremos\n",
        "    #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 0.0001), loss = 'binary_crossentropy', metrics= metrica)\n",
        "    history= model.fit(train_gen, batch_size= 1, epochs=epocas, validation_data=val_gen, callbacks=callbacks, initial_epoch= 6)#, class_weight= class_weights)\n",
        "\n",
        "def carga_mod(DIR):\n",
        "    return tf.keras.models.load_model(DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCwMORtF_xOB"
      },
      "outputs": [],
      "source": [
        "DIR_save_best= \"/content/drive/MyDrive/Sharon/ModeloGuardado/Kaggle/\"\n",
        "DIR_load_best= '/content/drive/MyDrive/Sharon/ModeloGuardado/Kaggle/08122021_CBAM.hdf5'\n",
        "\n",
        "model= carga_mod(DIR_load_best)\n",
        "entrenamient_modelo(ent_gen, val_gen, DIR_save_best, 300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vh5ZWseDno_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqrQTENfDm0H"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujYLQ-nYnvdY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDbdOw5mjprS"
      },
      "source": [
        "### Segmentación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwd4QaWEjrv4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Conv2DTranspose, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, History, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R_ewfBskdWz"
      },
      "outputs": [],
      "source": [
        "# Dirección del modelo y carga del modelo\n",
        "model_path= '/content/drive/MyDrive/Sharon/ModeloGuardado/Kaggle/09122021_CBAM.hdf5'\n",
        "\n",
        "model_2= tf.keras.models.load_model(model_path)\n",
        "#model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6SXHfXZ3slN"
      },
      "outputs": [],
      "source": [
        "input_im = Input(shape=(160, 160, 3)) # cifar 10 images size\n",
        "x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
        "\n",
        "  # 1st stage\n",
        "  # here we perform maxpooling, see the figure above\n",
        "\n",
        "x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "  #2nd stage \n",
        "  # frm here on only conv block and identity block, no pooling\n",
        "\n",
        "x = res_conv(x, s=1, filters=(64, 256))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(64, 256))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(64, 256))\n",
        "x= CBAM(x)\n",
        "  # 3rd stage\n",
        "\n",
        "x = res_conv(x, s=2, filters=(128, 512))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(128, 512))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(128, 512))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(128, 512))\n",
        "\n",
        "  # 4th stage\n",
        "\n",
        "x = res_conv(x, s=2, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(256, 1024), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "\n",
        "# 5th stage\n",
        "\n",
        "x = res_conv(x, s=2, filters=(512, 2048), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(512, 2048), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "x = res_identity(x, filters=(512, 2048), kern= tf.keras.regularizers.L2(0.01))\n",
        "x= CBAM(x)\n",
        "\n",
        "  # ends with average pooling and dense connection\n",
        "\n",
        "#x = AveragePooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "model= Model(inputs= input_im, outputs= x)\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-qaX7Wb2M5x"
      },
      "outputs": [],
      "source": [
        "for i, capa in enumerate(model_2.layers):\n",
        "  #print(i)\n",
        "  #print(capa)\n",
        "  #print('-----------------------------------')\n",
        "  if i < 481:\n",
        "    model.layers[i].set_weights= capa.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fguCaGMki9H"
      },
      "outputs": [],
      "source": [
        "def congelar_capas(model1):\n",
        "  for layer in model1.layers:\n",
        "    layer.trainable= True\n",
        "  return model1\n",
        "\n",
        "def cop_crong(modelo_ant, dir_a):\n",
        "  x= model.get_layer(dir_a)\n",
        "  return x.output\n",
        "\n",
        "def up_conc(capa, res):\n",
        "  x= UpSampling2D(2)(capa)\n",
        "  return concatenate([x, res])\n",
        "\n",
        "def conv_f(ker, x, nm):\n",
        "  x= Conv2D(ker, 3, padding= \"same\", activation= \"relu\", name= 'conv2d_'+ str(nm))(x)\n",
        "  x= BatchNormalization(name= 'batch_normalization_'+ str(nm))(x)\n",
        "  x= Conv2D(ker, 3, padding= \"same\", activation= \"relu\", name= 'conv2d_'+ str(nm+1))(x)\n",
        "  x= BatchNormalization(name= 'batch_normalization_'+ str(nm+1))(x)\n",
        "  return Conv2DTranspose(int(ker/2), 3, padding= \"same\")(x)\n",
        "\n",
        "def conv_v(ker, x, nm):\n",
        "  x= Conv2D(ker, 3, padding= \"same\", activation= \"relu\", name= 'conv2d_'+ str(nm))(x)\n",
        "  x= BatchNormalization(name= 'batch_normalization_'+ str(nm))(x)\n",
        "  x= Conv2D(ker, 3, padding= \"same\", activation= \"relu\", name= 'conv2d_'+ str(nm+1))(x)\n",
        "  x= BatchNormalization(name= 'batch_normalization_'+ str(nm+1))(x)\n",
        "  x= Conv2D(ker, 3, padding= \"same\", activation= \"relu\", name= 'conv2d_'+ str(nm+2))(x)\n",
        "  x= BatchNormalization(name= 'batch_normalization_'+ str(nm+2))(x)\n",
        "  return Conv2DTranspose(int(ker/2), 3, padding= \"same\")(x)\n",
        "\n",
        "def salida_d(ker, x, nm):\n",
        "  x= Conv2D(ker, 3, padding= \"same\", activation= \"relu\", name= 'conv2d_'+ str(nm))(x)\n",
        "  x= BatchNormalization(name= 'batch_normalization_'+ str(nm))(x)\n",
        "  x= Conv2D(ker/2, 3, padding= \"same\", activation= \"relu\", name= 'conv2d_'+ str(nm+1))(x)\n",
        "  x= BatchNormalization(name= 'batch_normalization_'+ str(nm+1))(x)\n",
        "  return Conv2D(2, 3, padding= \"same\", activation= \"softmax\", name= 'conv2d_'+ str(nm+2))(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqmtLJQVklsy"
      },
      "outputs": [],
      "source": [
        "#model_1= Model(inputs= model.inputs, outputs= model.layers[33].output)\n",
        "model= congelar_capas(model)\n",
        "\n",
        "x1= cop_crong(model, 'activation')\n",
        "x2= cop_crong(model, 'tf.math.add_35')\n",
        "x3= cop_crong(model, 'activation_42')\n",
        "x4= cop_crong(model, 'tf.math.add_53')\n",
        "x5= cop_crong(model, 'tf.math.add_59')\n",
        "\n",
        "x5= conv_v(1024, x5, 227)\n",
        "x6= up_conc(x5, x4)\n",
        "\n",
        "\n",
        "x7= conv_v(1024, x6, 240)\n",
        "x8= up_conc(x7, x3)\n",
        "\n",
        "x9= conv_f(512, x8, 289)\n",
        "x10= up_conc(x9, x2)\n",
        "\n",
        "\n",
        "x11= conv_f(256, x10, 298)\n",
        "x12= up_conc(x11, x1)\n",
        "\n",
        "x13= conv_f(128, x12, 300)\n",
        "x14= UpSampling2D(2)(x13)\n",
        "\n",
        "x15= salida_d(64, x14, 310)\n",
        "\n",
        "\n",
        "new_model= Model(inputs= model.input, outputs= x15)\n",
        "\n",
        "#new_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnXdLDKu2Gp9"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Sharon/Base de datos/Segmentacion/Hem/Val.zip\" -d \"/content/sample_data/\"\n",
        "!unzip \"/content/drive/MyDrive/Sharon/Base de datos/Segmentacion/Hem/Ent.zip\" -d \"/content/sample_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkWFCIX5kpzX"
      },
      "outputs": [],
      "source": [
        "ent_input_dir= \"/content/sample_data/Ent/org\"\n",
        "ent_target_dir= \"/content/sample_data/Ent/mask\"\n",
        "\n",
        "val_input_dir= \"/content/sample_data/Val/org\"\n",
        "val_target_dir= \"/content/sample_data/Val/mask\"\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(ent_input_dir, fname)\n",
        "        for fname in os.listdir(ent_input_dir) \n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(ent_target_dir, fname)\n",
        "        for fname in os.listdir(ent_target_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_input_paths = sorted(\n",
        "    [\n",
        "        os.path.join(val_input_dir, fname)\n",
        "        for fname in os.listdir(val_input_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_target_paths = sorted(\n",
        "    [\n",
        "        os.path.join(val_target_dir, fname)\n",
        "        for fname in os.listdir(val_target_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "ID_input_t= np.arange(len(input_img_paths))\n",
        "ID_input_v= np.arange(len(val_input_paths))\n",
        "\n",
        "print(len(input_img_paths))\n",
        "print(len(target_img_paths))\n",
        "print(len(val_target_paths))\n",
        "print(len(val_input_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3xXa6GilVGU"
      },
      "outputs": [],
      "source": [
        "#Generador de los ejemplos de entrada\n",
        "class MiClasificacion(tf.keras.utils.Sequence):\n",
        "    def __init__(self, input_img_paths, target_img_paths, ID_input, batch_size= 32, img_size= (304, 304, 3), train= True):\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        "        self.ID_input = ID_input\n",
        "        self.cont= 0\n",
        "\n",
        "    def __len__(self):\n",
        "        # Calcula el numero de pasos por epoca.\n",
        "        return len(self.ID_input) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
        "\n",
        "        # Combinamos los datos en cada epoca, pero solo para los datos de entrenamiento\n",
        "        if (self.cont== len(self.ID_input) // self.batch_size) or (self.cont== 0):\n",
        "            np.random.shuffle(self.ID_input)\n",
        "            self.cont= 0\n",
        "            \n",
        "        i = idx * self.batch_size\n",
        "        batch_img= []\n",
        "        batch_tar= []\n",
        "        self.cont += 1\n",
        "\n",
        "        #De acuerdo a los indices en ID_input tomamos las imagenes de los paths correspondientes\n",
        "        for ig in self.ID_input[i : i + self.batch_size]:\n",
        "            batch_img.append(self.input_img_paths[ig])\n",
        "            batch_tar.append(self.target_img_paths[ig])\n",
        "\n",
        "        X, Y= self.__data_generation(batch_img, batch_tar)                                          # Mandamos llamar a la funcion generadora de los ejemplos\n",
        "        \n",
        "        \n",
        "        #print(X.shape)\n",
        "        #print(Y.shape)\n",
        "        return X, Y\n",
        "\n",
        "    def __data_generation(self, biip, btip):\n",
        "            \n",
        "        # Creacion del tensor con dimensiones las dimensiones de entrada\n",
        "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")                   # Generamos un tensor que almacenara las imagenes importadas     \n",
        "        for j, path in enumerate(biip):\n",
        "            img = load_img(path, target_size=self.img_size)                                         # Cragamos las imagenes de entrada \n",
        "            x[j] = np.array(img)/255.0                                                              # Normalizamos y agregamos la imagen al tensor\n",
        "\n",
        "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")                      # Generamos un tensor que almacenara las mascaras importadas \n",
        "        for j, path in enumerate(btip):\n",
        "            img = load_img(path,target_size= self.img_size,color_mode=\"grayscale\")                  # Importamos la imagne en escala de grises\n",
        "            y[j] = np.expand_dims(img, 2)\n",
        "            for r in range(y.shape[1]):\n",
        "                for g in range(y.shape[2]):\n",
        "                    if y[j, r, g, 0]!= 0:                                                           # Nos aseguramos de que las venas etiquetadas resulten se un 1\n",
        "                        y[j, r, g, 0]= 1\n",
        "\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAkmdnkVldRZ"
      },
      "outputs": [],
      "source": [
        "def entrenamient_modelo(train_gen, val_gen, DIR_save, epocas= 30):\n",
        "\n",
        "    #Generamos los callback necesarios\n",
        "    checkpoint= ModelCheckpoint(DIR_save+ \"12122021_H_CBAM.hdf5\", monitor= 'val_loss', save_best_only= True, mode= 'min', save_weights_only= False)\n",
        "    #reduceLROnPlat= ReduceLROnPlateau(monitor= 'val_loss', factor= 0.8, patience= 5, min_delta= 0.001, cooldown= 10, min_lr= 0.0001)\n",
        "    #tensorboard_callback = TensorBoard(log_dir= datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    callbacks= [EarlyStopping(patience= 12,  monitor='val_loss'), History(), checkpoint]#, reduceLROnPlat, tensorboard_callback]\n",
        "\n",
        "    #Compilamos con la funcion perdida y el optimizador que utilizaremos\n",
        "    new_model.compile(optimizer=\"Adam\", loss= \"sparse_categorical_crossentropy\", metrics= ['accuracy']) #loss= \"binary_crossentropy\", metrics= ['accuracy'])\n",
        "    history= new_model.fit(train_gen, epochs=epocas, validation_data=val_gen, callbacks=callbacks)\n",
        "\n",
        "def carga_mod(DIR):\n",
        "    return tf.keras.models.load_model(DIR)\n",
        "\n",
        "img_size = (160, 160)\n",
        "num_classes = 2; batch_size_t = 16; batch_size_v = 16\n",
        "\n",
        "#Creamos los generadoras para el entrenamiento y la validación\n",
        "train_gen = MiClasificacion(\n",
        "    input_img_paths, target_img_paths, ID_input_t, batch_size= batch_size_t, img_size= img_size\n",
        ")\n",
        "\n",
        "val_gen = MiClasificacion(\n",
        "    val_input_paths, val_target_paths, ID_input_v, batch_size=batch_size_v, img_size= img_size\n",
        ")\n",
        "\n",
        "\n",
        "DIR_save_best= '/content/drive/MyDrive/Sharon/ModeloGuardado/Segmentacion/'\n",
        "#DIR_LOAD= '/content/drive/MyDrive/Sharon/ModeloGuardado/Segmentacion/09122021_H_CBAM.hdf5'\n",
        "\n",
        "#new_model= carga_mod(DIR_LOAD)\n",
        "entrenamient_modelo(train_gen, val_gen, DIR_save_best, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIh80vtEWY0U"
      },
      "source": [
        "#Resultados de la segmentacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOY2dMPeUSYU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from PIL import ImageOps\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "#from IPython.display import Image, display\n",
        "import PIL\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "civrXreKWh5l"
      },
      "outputs": [],
      "source": [
        "DIR= '/content/drive/MyDrive/Sharon/ModeloGuardado/Segmentacion/12122021_H_CBAM.hdf5'\n",
        "model= tf.keras.models.load_model(DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE6XedQBWjKO"
      },
      "outputs": [],
      "source": [
        "def cambio_tam(img, msk):\n",
        "  gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  gray = cv.GaussianBlur(gray, (7, 7), 3)\n",
        "  t, dst = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_TRIANGLE)\n",
        "  contours, _= cv.findContours(dst, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
        "  img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  a = []\n",
        "\n",
        "  for c in contours:\n",
        "    area = cv.contourArea(c)\n",
        "    a.append(area)\n",
        "        \n",
        "  for f in contours:\n",
        "    area = cv.contourArea(f)\n",
        "    if area == max(a):\n",
        "        x, y, w, h = cv.boundingRect(f)\n",
        "        imgr = img[y:y + h, x:x + w]\n",
        "        mask = msk[y:y + h, x:x + w]\n",
        "\n",
        "  return imgr, mask\n",
        "\n",
        "def prediccion_m(model, img, mostrar= False, h=0):\n",
        "  img= (np.array(img).reshape(-1,160,160,3))/255.0\n",
        "  val_preds = model.predict(img)\n",
        "  mask = np.argmax(val_preds[0], axis=-1)\n",
        "  mask = np.expand_dims(mask, axis=-1)\n",
        "  img = PIL.ImageOps.autocontrast(tf.keras.preprocessing.image.array_to_img(mask))\n",
        "  if mostrar== True:\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.show()\n",
        "  return img\n",
        "\n",
        "def equalize_clahe_color(img):\n",
        "    cla = cv.createCLAHE(clipLimit=1.5)     \n",
        "    channels = cv.split(img)     \n",
        "    eq_channels = []\n",
        "    for ch in channels:         \n",
        "        eq_channels.append(cla.apply(ch))     \n",
        "        eq_image = cv.merge(eq_channels)     \n",
        "    return eq_image\n",
        "\n",
        "def pre_procesamiento(img):\n",
        "    return cv.cvtColor(equalize_clahe_color(cv.cvtColor(img, cv.COLOR_BGR2RGB)), cv.COLOR_BGR2RGB)\n",
        "\n",
        "def prediccion_m(model, img):\n",
        "  img= (np.array(img).reshape(-1,160,160,3))/255.0\n",
        "  val_preds = model.predict(img)\n",
        "  mask = np.argmax(val_preds[0], axis=-1)\n",
        "  mask = np.expand_dims(mask, axis=-1)\n",
        "  img = PIL.ImageOps.autocontrast(tf.keras.preprocessing.image.array_to_img(mask))\n",
        "  \n",
        "  return np.array(img)\n",
        "\n",
        "# Genera los patches de entrada para el modelo\n",
        "def generar_patch(img, tam= 160):\n",
        "    f= []; g= 0; c= 0\n",
        "    for t in range(int(img.shape[0]/tam)):\n",
        "        for j in range(int(img.shape[1]/tam)):\n",
        "            f.append(img[g:g+ tam, c: c+ tam, :])\n",
        "            c+= tam\n",
        "        if img.shape[1]% tam != 0:\n",
        "            f.append(cv.resize(img[g:g+ tam, c: c+ (img.shape[1]-c), :], (tam, tam), interpolation = cv.INTER_AREA))\n",
        "        g+= tam; c= 0\n",
        "        \n",
        "    for t in range(int(img.shape[1]/tam)):\n",
        "        f.append(cv.resize(img[g:g+ (img.shape[0]- g), c: c+ tam, :], (tam, tam), interpolation = cv.INTER_AREA))\n",
        "        c+= tam\n",
        "    if img.shape[1]% tam != 0:\n",
        "        f.append(cv.resize(img[g:g+ (img.shape[0]-g), c: c+ (img.shape[1]-c), :], (tam,tam), interpolation = cv.INTER_AREA))\n",
        "    \n",
        "    return f\n",
        "\n",
        "def construccion_img(img, model, f, n= 0, c= 0, g= 0, tam= 160):\n",
        "    img_pred= np.zeros((img.shape[0], img.shape[1]))\n",
        "    for t in range(int(img.shape[0]/tam)):\n",
        "        for j in range(int(img.shape[1]/tam)):\n",
        "            p= prediccion_m(model, f[n])\n",
        "            img_pred[g: g+ tam, c: c+ tam]= p\n",
        "            c+= tam; n+= 1\n",
        "        if img.shape[1]% tam != 0:\n",
        "            p= cv.resize(prediccion_m(model, f[n]), (img.shape[1]-c, tam), interpolation = cv.INTER_AREA)\n",
        "            img_pred[g: g+ tam, c:]= p\n",
        "        g+= tam; c= 0; n+= 1\n",
        "        \n",
        "    for t in range(int(img.shape[1]/tam)):\n",
        "        p= cv.resize(prediccion_m(model, f[n]), (tam, img.shape[0]-g), interpolation = cv.INTER_AREA)\n",
        "        img_pred[g:, c: c+ tam]= p\n",
        "        c+= tam; n+= 1\n",
        "    if img.shape[1]% tam != 0:\n",
        "        p= cv.resize(prediccion_m(model, f[n]), (img.shape[1]-c, img.shape[0]-g), interpolation = cv.INTER_AREA)\n",
        "        img_pred[g:, c:]= p\n",
        "    \n",
        "    return img_pred\n",
        "\n",
        "def imagenes_comp(img, mask, s1= None, s2= None, s3= None, mostrar= False, guardar= False):\n",
        "  img_t= np.zeros((img.shape[0], img.shape[1], 3), dtype= np.float)\n",
        "  conv= np.zeros((img.shape[0], img.shape[1], 3), dtype= np.float)\n",
        "  img_t[:, :, 1]= img\n",
        "\n",
        "  conv[:,:,0]= mask[:,:,0]\n",
        "  conv[:,:,1]= img\n",
        "\n",
        "  if mostrar== True:\n",
        "    plt.imshow(img_t, cmap= 'gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.imshow(mask, cmap= 'gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.imshow(conv)\n",
        "    plt.show()\n",
        "  \n",
        "  if guardar== True:\n",
        "    plt.imsave(s1, img_t/255.0)\n",
        "    plt.imsave(s2, mask/255.0)\n",
        "    plt.imsave(s3, conv/255.0)\n",
        "\n",
        "\n",
        "def prediccion_final(model, DIR, DIR_M):\n",
        "  img= cv.imread(DIR)\n",
        "  mask= tf.keras.preprocessing.image.load_img(DIR_M)\n",
        "  mask= tf.keras.preprocessing.image.img_to_array(mask)\n",
        "\n",
        "  img, msk= cambio_tam(img, mask)\n",
        "  img= equalize_clahe_color(img)\n",
        "\n",
        "  f= generar_patch(img)\n",
        "  pred= construccion_img(img, model, f)\n",
        "\n",
        "  return pred, msk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zbhp13RWjGM"
      },
      "outputs": [],
      "source": [
        "DIR_M= \"/content/drive/MyDrive/Sharon/Base de datos/Pruebas/Hemorragias/mask/IDRiD_17_HE.tif\"\n",
        "DIR= \"/content/drive/MyDrive/Sharon/Base de datos/Pruebas/Hemorragias/org/IDRiD_17.jpg\"\n",
        "\n",
        "s1= \"/content/drive/MyDrive/Sharon/Base de datos/Pruebas/Hemorragias/com/p_res_cbam.png\"\n",
        "s2= \"/content/drive/MyDrive/Sharon/Base de datos/Pruebas/Hemorragias/com/m_res_cbam.png\"\n",
        "s3= \"/content/drive/MyDrive/Sharon/Base de datos/Pruebas/Hemorragias/com/conv_res_cbam.png\"\n",
        "\n",
        "pred, mask= prediccion_final(model, DIR, DIR_M)\n",
        "\n",
        "imagenes_comp(pred, mask, s1, s2, s3, True, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCyplORDWjAn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ResNet-50 CBAM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}